{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a notebook from Jun-Yan Zhu, a co-creator of the pix2pix GAN. \n",
    "### We will download and use software from Jun-Yan Zhu's git repo to train and test this model\n",
    "https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we must clone the git repo and install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRm-USlsHgEV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt3igws3eiVp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1EySlOXwwoa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch>=1.4.0\n",
      "  Downloading torch-2.0.0-cp39-cp39-win_amd64.whl (172.3 MB)\n",
      "     ------------------------------------- 172.3/172.3 MB 28.4 MB/s eta 0:00:00\n",
      "Collecting torchvision>=0.5.0\n",
      "  Downloading torchvision-0.15.1-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 74.1 MB/s eta 0:00:00\n",
      "Collecting dominate>=2.4.0\n",
      "  Downloading dominate-2.7.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting visdom>=0.1.8.8\n",
      "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 29.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.15.1-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 65.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\anaconda\\lib\\site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.3.0)\n",
      "Requirement already satisfied: networkx in c:\\anaconda\\lib\\site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\lib\\site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\lib\\site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.6.0)\n",
      "Requirement already satisfied: sympy in c:\\anaconda\\lib\\site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.10.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\anaconda\\lib\\site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (9.2.0)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\lib\\site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.21.5)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.28.1)\n",
      "Requirement already satisfied: scipy in c:\\anaconda\\lib\\site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.9.1)\n",
      "Requirement already satisfied: tornado in c:\\anaconda\\lib\\site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.1)\n",
      "Requirement already satisfied: six in c:\\anaconda\\lib\\site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.16.0)\n",
      "Collecting jsonpatch\n",
      "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: websocket-client in c:\\anaconda\\lib\\site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (0.58.0)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0\n",
      "  Downloading protobuf-4.22.4-cp39-cp39-win_amd64.whl (420 kB)\n",
      "     ---------------------------------------- 420.6/420.6 kB ? eta 0:00:00\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.22.1-py2.py3-none-any.whl (203 kB)\n",
      "     ---------------------------------------- 203.1/203.1 kB ? eta 0:00:00\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp39-cp39-win_amd64.whl (11 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\anaconda\\lib\\site-packages (from wandb->-r requirements.txt (line 5)) (5.9.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in c:\\anaconda\\lib\\site-packages (from wandb->-r requirements.txt (line 5)) (8.0.4)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\anaconda\\lib\\site-packages (from wandb->-r requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\lib\\site-packages (from wandb->-r requirements.txt (line 5)) (63.4.1)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "     ------------------------------------- 184.3/184.3 kB 10.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML in c:\\anaconda\\lib\\site-packages (from wandb->-r requirements.txt (line 5)) (6.0)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from Click!=8.0.0,>=7.0->wandb->-r requirements.txt (line 5)) (0.4.5)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\anaconda\\lib\\site-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda\\lib\\site-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (2.0.1)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\anaconda\\lib\\site-packages (from sympy->torch>=1.4.0->-r requirements.txt (line 1)) (1.2.1)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: visdom, pathtools\n",
      "  Building wheel for visdom (setup.py): started\n",
      "  Building wheel for visdom (setup.py): finished with status 'done'\n",
      "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408198 sha256=baef06dd37bf80526989ba9f4bff74231546141104c7e38ffac3330a0967f62b\n",
      "  Stored in directory: c:\\users\\gnunnelley\\appdata\\local\\pip\\cache\\wheels\\58\\9e\\14\\30f7cc4dafdd4d602fb00ca33c6edd1424fc0f5df10a02e060\n",
      "  Building wheel for pathtools (setup.py): started\n",
      "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8792 sha256=bd824150654f37930f65c4c2bf180d190c7182e2a1f3ca81228d95f4af873771\n",
      "  Stored in directory: c:\\users\\gnunnelley\\appdata\\local\\pip\\cache\\wheels\\b7\\0a\\67\\ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
      "Successfully built visdom pathtools\n",
      "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, protobuf, jsonpointer, dominate, docker-pycreds, torch, jsonpatch, gitdb, visdom, torchvision, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 dominate-2.7.0 gitdb-4.0.10 jsonpatch-1.32 jsonpointer-2.3 pathtools-0.1.2 protobuf-4.22.4 sentry-sdk-1.22.1 setproctitle-1.3.2 smmap-5.0.0 torch-2.0.0 torchvision-0.15.1 visdom-0.2.4 wandb-0.15.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\gnunnelley\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script visdom.exe is installed in 'C:\\Users\\gnunnelley\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts wandb.exe and wb.exe are installed in 'C:\\Users\\gnunnelley\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8daqlgVhw29P"
   },
   "source": [
    "# Datasets\n",
    "\n",
    "If you want, you can use their training data. This bash will download some canned datasets to play with.\n",
    "\n",
    "Or use your own dataset by creating the appropriate folders and adding in the images. Follow the instructions [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets).\n",
    "\n",
    "\n",
    "Download one of the official datasets with:\n",
    "\n",
    "-   `bash ./datasets/download_pix2pix_dataset.sh [cityscapes, night2day, edges2handbags, edges2shoes, facades, maps]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrdOettJxaCc"
   },
   "outputs": [],
   "source": [
    "#!bash ./datasets/download_pix2pix_dataset.sh facades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdUz4116xhpm"
   },
   "source": [
    "# Pretrained models\n",
    "\n",
    "similarly you can use a pretrained model, train using transfer learning from a pretrained model or \n",
    "\n",
    "add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`\n",
    "\n",
    "Download one of the official pretrained models with:\n",
    "\n",
    "-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n",
    "\n",
    "If you just want to create a new model from scratch, then all you need to do is make a new name for the \"--name\" feild in the training command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GC2DEP4M0OsS"
   },
   "outputs": [],
   "source": [
    "#!bash ./scripts/download_pix2pix_model.sh facades_label2photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sp7TCT2x9dB"
   },
   "outputs": [],
   "source": [
    "!python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
    "\n",
    "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
    "\n",
    "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
    "\n",
    "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mey7o6j-0368"
   },
   "outputs": [],
   "source": [
    "!ls checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCsKkEq0yGh0"
   },
   "outputs": [],
   "source": [
    "!python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_label2photo_pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzSKIPUByfiN"
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Mgg8raPyizq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G3oVH9DyqLQ"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_A.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErK5OC1j1LH4"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_B.png')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "pix2pix",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
